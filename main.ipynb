{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, syllable_count, hvc_neurons, syllable_features):\n",
    "        super(Model, self).__init__()\n",
    "        '''\n",
    "        Purpose:\n",
    "            - Initializes the song bird circuit \n",
    "            \n",
    "        Args:\n",
    "            - \n",
    "        \n",
    "        Returns:\n",
    "            - \n",
    "        '''\n",
    "\n",
    "        self.HVC_size = hvc_neurons\n",
    "        \n",
    "        # psuedo RNN\n",
    "        self.HVC = nn.Linear((syllable_count + hvc_neurons), hvc_neurons)\n",
    "\n",
    "        self.RA = nn.Linear(hvc_neurons, syllable_features)\n",
    "\n",
    "        self.LMAN_Size = syllable_features * 2\n",
    "        self.Area_X_size = hvc_neurons * self.LMAN_Size\n",
    "\n",
    "        # Technically, Area_X has RA * HVC amount of neurons, but for simplicity, we will assume that it is just RA * 1\n",
    "        self.Area_X =  nn.Linear(self.HVC_size, self.Area_X_size)\n",
    "        self.LMAN =  nn.Linear(self.Area_X_size, self.LMAN_Size)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "        self.clock = 0 \n",
    "\n",
    "    def forward_HVC(self, syllable, hvc_neurons):\n",
    "        x = self.HVC(torch.cat((syllable, hvc_neurons)))\n",
    "        return F.relu(x)\n",
    "    \n",
    "    def forward_RA(self, hvc_neurons):\n",
    "        x = self.RA(hvc_neurons)\n",
    "        return F.relu(x)\n",
    "    \n",
    "    def forward_Area_X(self, hvc_neurons):\n",
    "        x = self.Area_X(hvc_neurons)\n",
    "        return F.relu(x)\n",
    "    \n",
    "    def forward_LMAN(self, hvc_neurons):\n",
    "        x = self.LMAN(hvc_neurons)\n",
    "        return F.relu(x)\n",
    "    \n",
    "    def set_weights(self, layer, weight_matrix):\n",
    "        \"\"\"\n",
    "        Purpose:\n",
    "            - Sets the weights of the layer\n",
    "        \n",
    "        Args:\n",
    "            - layer: the layer to set the weights of\n",
    "            - weight_matrix: the weight matrix to set the weights to\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "\n",
    "        weight_matrix = nn.Parameter(weight_matrix)\n",
    "\n",
    "        if layer == \"HVC\":\n",
    "            self.HVC.weight = weight_matrix\n",
    "        if layer == \"RA\":\n",
    "            self.RA.weight = weight_matrix\n",
    "        if layer == \"Area_X\":\n",
    "            self.Area_X.weight = weight_matrix\n",
    "        if layer == \"LMAN\":\n",
    "            self.LMAN.weight = weight_matrix\n",
    "        \n",
    "    \n",
    "    def init_weights(self):\n",
    "        \"\"\"\n",
    "        Purpose:\n",
    "            - removes some weights between HVC_AreaX \n",
    "                - in areaX there are LMAN * HVC number of neurons\n",
    "                - each areaX neuron is connected to a unique combination of LMAN and HVC neurons\n",
    "            - removes weights between AreaX and LMAN\n",
    "                - many areaX neurons converge on a single LMAN neuron \n",
    "\n",
    "        Args:\n",
    "            None\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "\n",
    "        # set all weights between HVC and AreaX to 0\n",
    "        self.set_weights(\"Area_X\", torch.zeros(self.Area_X_size, self.HVC_size))\n",
    "\n",
    "        for i in range(self.Area_X_size):\n",
    "            for j in range(self.HVC_size):\n",
    "                # hard to explain see picture on my phone from apr 30 2023\n",
    "                if j == (i % self.HVC_size): \n",
    "                    # get weight matrix of AreaX\n",
    "                    weight_matrix = self.Area_X.weight\n",
    "                    weight_matrix = torch.tensor(weight_matrix)\n",
    "                    weight_matrix[i][j] = torch.rand(1)\n",
    "                    self.set_weights(\"Area_X\", weight_matrix)\n",
    "\n",
    "        # set all weights between AreaX and LMAN to 0\n",
    "        self.set_weights(\"LMAN\", torch.zeros(self.LMAN_Size, self.Area_X_size))\n",
    "\n",
    "        for i in range(self.LMAN_Size):\n",
    "            start = i * self.HVC_size\n",
    "            stop = start + self.HVC_size\n",
    "            for j in range(start, stop):\n",
    "                weight_matrix = self.LMAN.weight\n",
    "                weight_matrix = torch.tensor(weight_matrix)\n",
    "                weight_matrix[i][j] = torch.rand(1)\n",
    "                self.set_weights(\"LMAN\", weight_matrix)\n",
    "              \n",
    "\n",
    "    def hebbian_update(self, pre_layer_activations, post_layer_activations, learning_rate):\n",
    "        \"\"\"\n",
    "        Purpose:\n",
    "            - if the pre_layer and post_layer fire in the same cycle, then the weights between them are updated by the learning rate in positive direction\n",
    "            - if not, then the weights are updated in negative direction by the learning rate\n",
    "\n",
    "        Args:\n",
    "            - pre_layer_activations: the activations of the pre layer\n",
    "            - post_layer_activations: the activations of the post layer\n",
    "\n",
    "        Returns:\n",
    "            - post_weights: the updated weights between the pre and post layer (belongs to the post layer)\n",
    "        \"\"\"\n",
    "\n",
    "        post_weights = torch.zeros(len(pre_layer_activations), len(post_layer_activations))\n",
    "\n",
    "        for i in range(len(pre_layer_activations)):\n",
    "            for j in range(len(post_layer_activations)):\n",
    "                if pre_layer_activations[i] != 0 and post_layer_activations[j] != 0:\n",
    "                    post_weights[i][j] += learning_rate\n",
    "                else:\n",
    "                    post_weights[i][j] -= learning_rate\n",
    "\n",
    "        return post_weights \n",
    "\n",
    "    def HVC_X_update_rule(self):\n",
    "        pass\n",
    "\n",
    "    def visualize_layer_weights(self, layer):\n",
    "        \"\"\"\n",
    "        Purpose:\n",
    "            - Visualizes the weights of the layer\n",
    "\n",
    "        Args:\n",
    "            - layer: the layer to visualize\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "\n",
    "        if layer == \"HVC\":\n",
    "            weights = self.HVC.weight\n",
    "        elif layer == \"RA\":\n",
    "            weights = self.RA.weight\n",
    "        elif layer == \"Area_X\":\n",
    "            weights = self.Area_X.weight\n",
    "        elif layer == \"LMAN\":\n",
    "            weights = self.LMAN.weight\n",
    "        \n",
    "        weights = weights.detach().numpy()\n",
    "        fig, ax = plt.subplots()\n",
    "        im = ax.imshow(weights, cmap='coolwarm')\n",
    "\n",
    "        # Add a colorbar to the heatmap\n",
    "        cbar = ax.figure.colorbar(im, ax=ax)\n",
    "\n",
    "        # Add value labels to the heatmap\n",
    "        for i in range(weights.shape[0]):\n",
    "            for j in range(weights.shape[1]):\n",
    "                ax.text(j, i, '{:.2f}'.format(weights[i, j]), ha='center', va='center', color='w')\n",
    "\n",
    "        # Add a title and axis labels to the heatmap\n",
    "        ax.set_title('Weight Matrix Heatmap')\n",
    "        ax.set_xlabel('Input Features')\n",
    "        ax.set_ylabel('Output Features')\n",
    "\n",
    "        # Show the heatmap\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def print_layer_weights(self, layer):\n",
    "        \"\"\"\n",
    "        Purpose:\n",
    "            - Prints the weights of the layer in a heatmap format\n",
    "\n",
    "        Args:\n",
    "            - layer: the layer to print\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "\n",
    "        if layer == \"HVC\":\n",
    "            weights = self.HVC.weight\n",
    "        if layer == \"RA\":\n",
    "            weights = self.RA.weight\n",
    "        if layer == \"Area_X\":\n",
    "            weights = self.Area_X.weight\n",
    "        if layer == \"LMAN\":\n",
    "            weights = self.LMAN.weight\n",
    "        \n",
    "        print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class train_env():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def generate_syllables(self, syllable_count):\n",
    "        '''\n",
    "        Purpose: \n",
    "            - Generate syllables for training\n",
    "            - 4 params for syllable generation, freq, amplitude, y-offset, length\n",
    "        Input: \n",
    "            - Number of syllables to generate\n",
    "        Output: \n",
    "            - returns songs as a numpy array of shape (syllable_count * individual lengths, 3)\n",
    "            - returns length of each syllable \n",
    "        ''' \n",
    "\n",
    "        self.syllable_count = syllable_count\n",
    "\n",
    "        # careful, the code below is cringe af!\n",
    "        syllable_duration = np.random.uniform(3, 10, syllable_count)\n",
    "        syllable_duration = np.array(syllable_duration, dtype=int)\n",
    "        self.syllable_lengths = syllable_duration\n",
    "\n",
    "        total_syllable_length = np.sum(syllable_duration)\n",
    "\n",
    "        syllables = np.zeros((total_syllable_length, 3))\n",
    "        self.syllable_index = np.zeros((total_syllable_length, 1))\n",
    "        \n",
    "        cum_length = 0\n",
    "        for i, length in enumerate(syllable_duration):\n",
    "            self.syllable_index[cum_length:cum_length+length] = i\n",
    "            freq = np.random.uniform(0, 1)\n",
    "            amp = np.random.uniform(0, 1)\n",
    "            y_offset = np.random.uniform(0, 1)\n",
    "            for t in range(length):\n",
    "                syllables[cum_length, 0] = freq\n",
    "                syllables[cum_length, 1] = amp\n",
    "                syllables[cum_length, 2] = y_offset\n",
    "                cum_length += 1\n",
    "\n",
    "        self.syllables = syllables\n",
    "\n",
    "        self.num_syllables = syllable_count\n",
    "\n",
    "        return syllables, syllable_duration\n",
    "\n",
    "    def generate_train_set(self, train_size):\n",
    "        '''\n",
    "        Purpose:\n",
    "            - Generate a training set for the model\n",
    "        Input:\n",
    "            - train_size: number of training examples to generate\n",
    "        Output:\n",
    "            - train_set: a list of training examples\n",
    "        '''\n",
    "        output_set = []\n",
    "        input_set = []\n",
    "\n",
    "        for i in range(train_size):\n",
    "            # self.syllables.shape[0] is the the total num of timesteps \n",
    "            padded_syllables = np.zeros((self.syllables.shape[0], 3))\n",
    "            padded_HVC_on = np.zeros((self.syllables.shape[0], self.syllable_count))\n",
    "\n",
    "    \n",
    "            lower_bound_syllable_index = np.random.randint(0, self.num_syllables)\n",
    "            upper_bound_syllable_index = np.random.randint(lower_bound_syllable_index, self.num_syllables)\n",
    "\n",
    "            if lower_bound_syllable_index != upper_bound_syllable_index:\n",
    "                list_of_syllables_indices = [i for i in range(lower_bound_syllable_index, upper_bound_syllable_index)]\n",
    "            else:\n",
    "                list_of_syllables_indices = [lower_bound_syllable_index]\n",
    "\n",
    "            # create a list of first timestep of each syllable\n",
    "            list_of_first_timestep_per_syllable = []\n",
    "\n",
    "            for syllable_index in list_of_syllables_indices:\n",
    "                first_timestep = np.sum(self.syllable_lengths[:syllable_index])\n",
    "                list_of_first_timestep_per_syllable.append(first_timestep)\n",
    "\n",
    "        \n",
    "            # set the HVC_on to 1 for the interval\n",
    "            for i, syllable in enumerate(list_of_syllables_indices):\n",
    "                padded_HVC_on[list_of_first_timestep_per_syllable[i]:list_of_first_timestep_per_syllable[i]+self.syllable_lengths[syllable], syllable] = 1\n",
    "\n",
    "            for syllable in list_of_syllables_indices:\n",
    "                padded_syllables[list_of_first_timestep_per_syllable[i]:list_of_first_timestep_per_syllable[i]+self.syllable_lengths[syllable], :] = self.syllables[list_of_first_timestep_per_syllable[i]:list_of_first_timestep_per_syllable[i]+self.syllable_lengths[syllable], :]\n",
    "          \n",
    "            # padded to tensor\n",
    "            padded_syllables = torch.from_numpy(padded_syllables).float()\n",
    "            padded_HVC_on = torch.from_numpy(padded_HVC_on).float()\n",
    "\n",
    "            output_set.append(padded_syllables)\n",
    "            input_set.append(padded_HVC_on)\n",
    "\n",
    "        return output_set, input_set\n",
    "\n",
    "\n",
    "    def train(self, model, epochs, train_size):\n",
    "        '''\n",
    "        Purpose:\n",
    "            - Train the model\n",
    "        Input:\n",
    "            - model\n",
    "            - train_loader\n",
    "            - epochs\n",
    "        Output:\n",
    "            - trained model\n",
    "        ''' \n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        output_set, input_set = self.generate_train_set(train_size)\n",
    "\n",
    "        for epoch in range(epochs): \n",
    "            for i in range(train_size):\n",
    "                optimizer.zero_grad()\n",
    "                output, hidden = model(input_set[i])\n",
    "                loss = criterion(output, output_set[i])\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        pass\n",
    "\n",
    "    def get_syllables(self):\n",
    "        return self.syllables\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Grounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s5/0yhgng1n5k12_prdv1mgd4hw0000gn/T/ipykernel_1843/3148271964.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  weight_matrix = torch.tensor(weight_matrix)\n",
      "/var/folders/s5/0yhgng1n5k12_prdv1mgd4hw0000gn/T/ipykernel_1843/3148271964.py:111: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  weight_matrix = torch.tensor(weight_matrix)\n"
     ]
    }
   ],
   "source": [
    "hvc_neurons = 1\n",
    "syllable_features = 1\n",
    "syllable_count = 1\n",
    "epochs = 10 \n",
    "\n",
    "model = Model(syllable_count, hvc_neurons, syllable_features)\n",
    "\n",
    "dummy_HVC_input = torch.zeros(syllable_count)\n",
    "\n",
    "# initial hidden state\n",
    "hidden_state = torch.zeros(hvc_neurons)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # HVC -> RA -> RA_output\n",
    "    hidden_state = model.forward_HVC(dummy_HVC_input, hidden_state)\n",
    "    ra_output = model.forward_RA(hidden_state)\n",
    "\n",
    "    # HVC -> Area_X -> LMAN (random normal for now)\n",
    "    Area_X_output = model.forward_Area_X(hidden_state)\n",
    "    LMAN_output = model.forward_LMAN(Area_X_output)\n",
    "\n",
    "    # RA_output = RA_output + LMAN bias \n",
    "    RA_output = ra_output + LMAN_output\n",
    "\n",
    "    # calculate reward \n",
    "\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
